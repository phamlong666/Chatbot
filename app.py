# -*- coding: utf-8 -*-
import streamlit as st
import gspread
from google.oauth2.service_account import Credentials
from openai import OpenAI
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import re
import os
from pathlib import Path
import fuzzywuzzy.fuzz as fuzz
import datetime
import easyocr
import json
import speech_recognition as sr
import tempfile
import numpy as np
from cryptography.fernet import Fernet
from audio_recorder_streamlit import audio_recorder
from difflib import get_close_matches
# Th√™m import m·ªõi cho bi·ªÉu ƒë·ªì
import seaborn as sns
from oauth2client.service_account import ServiceAccountCredentials


# C·∫•u h√¨nh Streamlit page ƒë·ªÉ s·ª≠ d·ª•ng layout r·ªông
st.set_page_config(layout="wide")

# C·∫•u h√¨nh Matplotlib ƒë·ªÉ hi·ªÉn th·ªã ti·∫øng Vi·ªát
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['font.size'] = 14
plt.rcParams['axes.labelsize'] = 14
plt.rcParams['axes.titlesize'] = 14
plt.rcParams['xtick.labelsize'] = 14
plt.rcParams['ytick.labelsize'] = 14
plt.rcParams['figure.titlesize'] = 16

# K·∫øt n·ªëi Google Sheets v·ªõi private key ƒë√£ ƒë∆∞·ª£c m√£ h√≥a
SCOPES = ["https://www.googleapis.com/auth/spreadsheets"]

if "gdrive_service_account" in st.secrets:
    try:
        encryption_key_for_decryption = st.secrets["gdrive_service_account"].get("encryption_key_for_decryption")
        encrypted_private_key = st.secrets["gdrive_service_account"].get("encrypted_private_key")

        if not encryption_key_for_decryption or not encrypted_private_key:
            raise ValueError("Thi·∫øu encryption_key ho·∫∑c encrypted_private_key trong secrets.toml")

        f = Fernet(encryption_key_for_decryption.encode())
        decrypted_private_key = f.decrypt(encrypted_private_key.encode()).decode()

        info = {
            "type": st.secrets["gdrive_service_account"]["type"],
            "project_id": st.secrets["gdrive_service_account"]["project_id"],
            "private_key_id": st.secrets["gdrive_service_account"]["private_key_id"],
            "private_key": decrypted_private_key,
            "client_email": st.secrets["gdrive_service_account"]["client_email"],
            "client_id": st.secrets["gdrive_service_account"]["client_id"],
            "auth_uri": st.secrets["gdrive_service_account"]["auth_uri"],
            "token_uri": st.secrets["gdrive_service_account"]["token_uri"],
            "auth_provider_x509_cert_url": st.secrets["gdrive_service_account"]["auth_provider_x509_cert_url"],
            "client_x509_cert_url": st.secrets["gdrive_service_account"]["client_x509_cert_url"]
        }

        creds = Credentials.from_service_account_info(info, scopes=SCOPES)
        client = gspread.authorize(creds)
        # ƒê√£ x√≥a d√≤ng hi·ªÉn th·ªã th√¥ng b√°o k·∫øt n·ªëi th√†nh c√¥ng
        # st.success("‚úÖ ƒê√£ k·∫øt n·ªëi Google Sheets th√†nh c√¥ng!")

    except Exception as e:
        st.error(f"‚ùå L·ªói khi gi·∫£i m√£ ho·∫∑c k·∫øt n·ªëi Google Sheets: {e}. Vui l√≤ng ki·ªÉm tra l·∫°i c·∫•u h√¨nh secrets.toml.")
        st.stop()
else:
    st.error("‚ùå Kh√¥ng t√¨m th·∫•y 'gdrive_service_account' trong secrets. Vui l√≤ng c·∫•u h√¨nh.")
    st.stop()

# L·∫•y API key OpenAI
openai_api_key = None
if "openai_api_key" in st.secrets:
    openai_api_key = st.secrets["openai_api_key"]
    st.success("‚úÖ ƒê√£ k·∫øt n·ªëi OpenAI API key t·ª´ Streamlit secrets.")
else:
    pass # Kh√¥ng hi·ªÉn th·ªã c·∫£nh b√°o n·ªØa

if openai_api_key:
    client_ai = OpenAI(api_key=openai_api_key)
else:
    client_ai = None

spreadsheet_url = "https://docs.google.com/spreadsheets/d/13MqQzvV3Mf9bLOAXwICXclYVQ-8WnvBDPAR8VJfOGJg/edit"

# H√†m ƒë·ªÉ t√¨m t√™n c·ªôt ch√≠nh x√°c, s·ª≠ d·ª•ng fuzzy matching
def find_column_name(df, possible_names, threshold=80):
    """
    T√¨m t√™n c·ªôt ch√≠nh x√°c trong DataFrame t·ª´ m·ªôt danh s√°ch c√°c t√™n c√≥ th·ªÉ.
    S·ª≠ d·ª•ng fuzzy matching ƒë·ªÉ t√¨m ki·∫øm linh ho·∫°t h∆°n.
    """
    df_cols = [col.strip().lower() for col in df.columns]
    for name in possible_names:
        name_lower = name.strip().lower()
        # D√πng fuzzy search ƒë·ªÉ t√¨m t√™n c·ªôt ph√π h·ª£p nh·∫•t
        matches = get_close_matches(name_lower, df_cols, n=1, cutoff=threshold/100)
        if matches:
            # L·∫•y t√™n c·ªôt g·ªëc t·ª´ DataFrame
            original_col_name = df.columns[df_cols.index(matches[0])]
            return original_col_name
    return None

# H√†m ƒë·ªÉ l·∫•y d·ªØ li·ªáu t·ª´ m·ªôt sheet c·ª• th·ªÉ
def get_sheet_data(sheet_name):
    try:
        sheet = client.open_by_url(spreadsheet_url).worksheet(sheet_name)
        all_values = sheet.get_all_values()
        if all_values:
            headers = all_values[0]
            # ƒê·∫£m b·∫£o ti√™u ƒë·ªÅ duy nh·∫•t
            seen_headers = {}
            unique_headers = []
            for h in headers:
                original_h = h
                count = seen_headers.get(h, 0)
                while h in seen_headers and seen_headers[h] > 0:
                    h = f"{original_h}_{count}"
                    count += 1
                seen_headers[original_h] = seen_headers.get(original_h, 0) + 1
                unique_headers.append(h)

            data = all_values[1:]
            df_temp = pd.DataFrame(data, columns=unique_headers)
            return df_temp
        else:
            return pd.DataFrame() # Return empty DataFrame if no values
    except gspread.exceptions.WorksheetNotFound:
        st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y sheet '{sheet_name}'. Vui l√≤ng ki·ªÉm tra t√™n sheet.")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"‚ùå L·ªói khi m·ªü Google Sheet '{sheet_name}': {e}. Vui l√≤ng ki·ªÉm tra ƒë·ªãnh d·∫°ng ti√™u ƒë·ªÅ c·ªßa sheet. N·∫øu c√≥ ti√™u ƒë·ªÅ tr√πng l·∫∑p, h√£y ƒë·∫£m b·∫£o ch√∫ng l√† duy nh·∫•t.")
        return pd.DataFrame()

# H√†m chu·∫©n h√≥a chu·ªói ƒë·ªÉ so s√°nh ch√≠nh x√°c h∆°n (lo·∫°i b·ªè d·∫•u c√°ch th·ª´a, chuy·ªÉn v·ªÅ ch·ªØ th∆∞·ªùng)
def normalize_text(text):
    if isinstance(text, str):
        # Chuy·ªÉn v·ªÅ ch·ªØ th∆∞·ªùng, lo·∫°i b·ªè d·∫•u c√°ch th·ª´a ·ªü ƒë·∫ßu/cu·ªëi v√† thay th·∫ø nhi·ªÅu d·∫•u c√°ch b·∫±ng m·ªôt d·∫•u c√°ch
        return re.sub(r'\s+', ' ', text).strip().lower()
    return ""

# T·∫£i d·ªØ li·ªáu t·ª´ sheet "H·ªèi-Tr·∫£ l·ªùi" m·ªôt l·∫ßn khi ·ª©ng d·ª•ng kh·ªüi ƒë·ªông
qa_data = get_sheet_data("H·ªèi-Tr·∫£ l·ªùi")
qa_df = pd.DataFrame(qa_data) if qa_data is not None else pd.DataFrame() # Ensure qa_data is not None

# H√†m l·∫•y d·ªØ li·ªáu t·ª´ t·∫•t c·∫£ sheet trong file
@st.cache_data
def load_all_sheets():
    spreadsheet = client.open_by_url(spreadsheet_url)
    sheet_names = [ws.title for ws in spreadsheet.worksheets()]
    data = {}
    for name in sheet_names:
        try:
            # Use get_sheet_data to handle specific sheet types
            df = get_sheet_data(name) 
            data[name] = df
        except Exception as e: # Catch any error during DataFrame creation
            st.warning(f"‚ö†Ô∏è L·ªói khi t·∫£i sheet '{name}': {e}. ƒêang b·ªè qua sheet n√†y.")
            data[name] = pd.DataFrame() # Ensure an empty DataFrame is returned on error
    return data

all_data = load_all_sheets()

# H√†m ƒë·ªÉ ƒë·ªçc c√¢u h·ªèi t·ª´ file JSON
def load_sample_questions(file_path="sample_questions.json"):
    try:
        # ƒê√£ thay ƒë·ªïi: ƒê·ªçc file JSON thay v√¨ s·ª≠ d·ª•ng danh s√°ch c·ªë ƒë·ªãnh
        with open(file_path, "r", encoding="utf-8") as f:
            questions_data = json.load(f)
        return questions_data
    except FileNotFoundError:
        st.error(f"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file c√¢u h·ªèi m·∫´u t·∫°i ƒë∆∞·ªùng d·∫´n: {file_path}. Vui l√≤ng ƒë·∫£m b·∫£o file 'sample_questions.json' n·∫±m c√πng th∆∞ m·ª•c v·ªõi file app.py c·ªßa b·∫°n khi tri·ªÉn khai.")
        return []
    except json.JSONDecodeError:
        st.error(f"‚ùå L·ªói: File '{file_path}' kh√¥ng ph·∫£i l√† ƒë·ªãnh d·∫°ng JSON h·ª£p l·ªá. Vui l√≤ng ki·ªÉm tra l·∫°i n·ªôi dung file.")
        return []
    except Exception as e:
        st.error(f"‚ùå L·ªói khi ƒë·ªçc danh s√°ch c√¢u h·ªèi m·∫´u t·ª´ file: {e}")
        return []

# T·∫£i c√°c c√¢u h·ªèi m·∫´u khi ·ª©ng d·ª•ng kh·ªüi ƒë·ªông
sample_questions_from_file = load_sample_questions()

# --- Handler t·ªïng qu√°t: KPI c√°c ƒë∆°n v·ªã th√°ng mm/nƒÉm yyyy (gi·∫£m d·∫ßn) ---
def handle_kpi_monthly(question: str) -> bool:
    # B·∫Øt c√¢u: 'L·∫•y th√¥ng tin KPI c·ªßa c√°c ƒë∆°n v·ªã th√°ng mm nƒÉm yyyy v√† s·∫Øp x·∫øp theo th·ª© t·ª± gi·∫£m d·∫ßn'.
    # Tr·∫£ v·ªÅ True n·∫øu ƒë√£ x·ª≠ l√Ω (k·ªÉ c·∫£ khi kh√¥ng c√≥ d·ªØ li·ªáu), False n·∫øu kh√¥ng kh·ªõp.
    try:
        normalized = normalize_text(question)
        # Cho ph√©p c√≥/kh√¥ng c·ª•m 'v√† s·∫Øp x·∫øp theo th·ª© t·ª± gi·∫£m d·∫ßn'
        pattern = r"l·∫•y th√¥ng tin kpi c·ªßa c√°c ƒë∆°n v·ªã th√°ng\s*(\d{1,2})\s*nƒÉm\s*(\d{4})(?:.*?s·∫Øp x·∫øp theo th·ª© t·ª± gi·∫£m d·∫ßn|.*?)$"
        m = re.search(pattern, normalized)
        if not m:
            return False

        month = int(m.group(1))
        year = int(m.group(2))
        if month < 1 or month > 12:
            st.warning("‚ùó Th√°ng kh√¥ng h·ª£p l·ªá. Vui l√≤ng nh·∫≠p th√°ng t·ª´ 1‚Äì12.")
            return True

        sheet_name = "KPI"
        sheet_data = all_data.get(sheet_name)
        if sheet_data is None or sheet_data.empty:
            st.warning(f"‚ö†Ô∏è Sheet '{sheet_name}' kh√¥ng c√≥ d·ªØ li·ªáu ho·∫∑c kh√¥ng th·ªÉ ƒë·ªçc ƒë∆∞·ª£c.")
            return True

        df = sheet_data.copy()

        # T√¨m t√™n c·ªôt linh ho·∫°t
        kpi_col   = find_column_name(df, ['ƒêi·ªÉm KPI', 'KPI'])
        nam_col   = find_column_name(df, ['NƒÉm'])
        thang_col = find_column_name(df, ['Th√°ng'])
        donvi_col = find_column_name(df, ['ƒê∆°n v·ªã', 'ƒê∆°n v·ªã/ƒê·ªãa b√†n'])

        if not all([kpi_col, nam_col, thang_col, donvi_col]):
            st.warning(f"‚ùó Kh√¥ng t√¨m th·∫•y ƒë·∫ßy ƒë·ªß c·ªôt (NƒÉm, Th√°ng, ƒê∆°n v·ªã, ƒêi·ªÉm KPI) trong sheet {sheet_name}.")
            return True

        # Chu·∫©n h√≥a s·ªë
        df[kpi_col]   = df[kpi_col].astype(str).str.replace(',', '.', regex=False)
        df[kpi_col]   = pd.to_numeric(df[kpi_col], errors='coerce')
        df[nam_col]   = pd.to_numeric(df[nam_col], errors='coerce')
        df[thang_col] = pd.to_numeric(df[thang_col], errors='coerce')

        # L·ªçc d·ªØ li·ªáu th√°ng/nƒÉm
        df_filtered = df[(df[nam_col] == year) & (df[thang_col] == month)].copy()

        if df_filtered.empty:
            st.warning(f"‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu KPI cho th√°ng {month:02d}/{year}.")
            return True

        # S·∫Øp x·∫øp gi·∫£m d·∫ßn theo KPI
        df_sorted = df_filtered.sort_values(by=kpi_col, ascending=False)

        st.subheader(f"üìä KPI c√°c ƒë∆°n v·ªã th√°ng {month:02d}/{year} (s·∫Øp x·∫øp gi·∫£m d·∫ßn)")
        st.dataframe(df_sorted[[donvi_col, thang_col, nam_col, kpi_col]].reset_index(drop=True))

        # V·∫Ω bi·ªÉu ƒë·ªì theo ƒë√∫ng th·ª© t·ª± ƒë√£ s·∫Øp
        plt.figure(figsize=(12, 7))
        import seaborn as sns  # ƒë·∫£m b·∫£o c√≥ sns trong ph·∫°m vi h√†m
        ax = sns.barplot(
            data=df_sorted,
            x=donvi_col,
            y=kpi_col,
            order=df_sorted[donvi_col].tolist(),
            palette="tab10"
        )
        plt.title(f"KPI th√°ng {month:02d}/{year} theo ƒë∆°n v·ªã (gi·∫£m d·∫ßn)")
        plt.xlabel("ƒê∆°n v·ªã")
        plt.ylabel("ƒêi·ªÉm KPI")
        plt.xticks(rotation=45, ha='right')

        # Ghi nh√£n gi√° tr·ªã tr√™n c·ªôt
        for p in ax.patches:
            height = p.get_height()
            ax.annotate(f'{height:.2f}',
                        (p.get_x() + p.get_width()/2., height),
                        ha='center', va='center',
                        xytext=(0, 10), textcoords='offset points',
                        fontsize=10, fontweight='bold')

        plt.tight_layout()
        st.pyplot(plt)
        plt.close()

        return True
    except Exception as e:
        st.error(f"‚ùå L·ªói khi x·ª≠ l√Ω KPI th√°ng mm/nƒÉm yyyy: {e}")
        return True




# --- B·∫Øt ƒë·∫ßu b·ªë c·ª•c m·ªõi: Logo ·ªü tr√°i, ph·∫ßn c√≤n l·∫°i c·ªßa chatbot cƒÉn gi·ªØa ---

# Ph·∫ßn header: Logo v√† ti√™u ƒë·ªÅ, ƒë∆∞·ª£c ƒë·∫∑t ·ªü ƒë·∫ßu trang v√† logo cƒÉn tr√°i
header_col1, header_col2 = st.columns([1, 8]) # T·ª∑ l·ªá cho logo v√† ti√™u ƒë·ªÅ

with header_col1:
    public_logo_url = "https://raw.githubusercontent.com/phamlong666/Chatbot/main/logo_hinh_tron.png"
    try:
        st.image(public_logo_url, width=100) # K√≠ch th∆∞·ªõc 100px
    except Exception as e_public_url:
        st.error(f"‚ùå L·ªói khi hi·ªÉn th·ªã logo t·ª´ URL: {e_public_url}. Vui l√≤ng ƒë·∫£m b·∫£o URL l√† li√™n k·∫øt TR·ª∞C TI·∫æP ƒë·∫øn file ·∫£nh (k·∫øt th√∫c b·∫±ng .jpg, .png, v.v.) v√† ki·ªÉm tra k·∫øt n·ªëi internet.")
        logo_path = Path(__file__).parent / "logo_hinh_tron.jpg"
        try:
            if logo_path.exists():
                st.image(str(logo_path), width=100)
            else:
                st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y file ·∫£nh logo t·∫°i: {logo_path}. Vui l√≤ng ƒë·∫£m b·∫£o file 'logo_hinh_tron.jpg' n·∫±m c√πng th∆∞ m·ª•c v·ªõi file app.py c·ªßa b·∫°n khi tri·ªÉn khai.")
        except Exception as e_local_file:
            st.error(f"‚ùå L·ªói khi hi·ªÉn th·ªã ·∫£nh logo t·ª´ file c·ª•c b·ªô: {e_local_file}.")

with header_col2:
    # ƒê√£ thay ƒë·ªïi st.title th√†nh st.markdown ƒë·ªÉ t√πy ch·ªânh c·ª° ch·ªØ
    st.markdown("<h1 style='font-size: 30px;'>ü§ñ Chatbot ƒê·ªôi QLƒêLKV ƒê·ªãnh H√≥a</h1>", unsafe_allow_html=True)

# Ph·∫ßn n·ªôi dung ch√≠nh c·ªßa chatbot (√¥ nh·∫≠p li·ªáu, n√∫t, k·∫øt qu·∫£) s·∫Ω ƒë∆∞·ª£c cƒÉn gi·ªØa
# T·∫°o 3 c·ªôt: c·ªôt tr√°i r·ªóng (ƒë·ªÉ t·∫°o kho·∫£ng tr·ªëng), c·ªôt gi·ªØa ch·ª©a n·ªôi dung chatbot, c·ªôt ph·∫£i r·ªóng
# ƒê√£ thay ƒë·ªïi t·ª∑ l·ªá t·ª´ [1, 3, 1] sang [1, 5, 1] ƒë·ªÉ m·ªü r·ªông kh√¥ng gian chat
col_left_spacer, col_main_content, col_right_spacer = st.columns([1, 5, 1])

with col_main_content: # T·∫•t c·∫£ n·ªôi dung chatbot s·∫Ω n·∫±m trong c·ªôt n√†y
    # Kh·ªüi t·∫°o session state ƒë·ªÉ l∆∞u tr·ªØ tin nh·∫Øn cu·ªëi c√πng ƒë√£ x·ª≠ l√Ω
    if 'last_processed_user_msg' not in st.session_state:
        st.session_state.last_processed_user_msg = ""
    if 'qa_results' not in st.session_state:
        st.session_state.qa_results = []
    if 'qa_index' not in st.session_state:
        st.session_state.qa_index = 0
    if 'user_input_value' not in st.session_state: # S·ª≠ d·ª•ng user_input_value l√†m key ch√≠nh cho input
        st.session_state.user_input_value = ""
    if 'current_qa_display' not in st.session_state: # NEW: To hold the currently displayed QA answer
        st.session_state.current_qa_display = ""
    # ‚úÖ Ghi √¢m n·∫±m ngo√†i form, x·ª≠ l√Ω tr·∫°ng th√°i v·ªõi session_state
    if "audio_processed" not in st.session_state:
        st.session_state.audio_processed = False

    audio_bytes = audio_recorder(
        text="üéô Nh·∫•n ƒë·ªÉ n√≥i",
        recording_color="#e8b62c",
        neutral_color="#6aa36f",
        icon_size="2x"
    )

    if audio_bytes and not st.session_state.audio_processed:
        st.info("‚è≥ ƒêang x·ª≠ l√Ω gi·ªçng n√≥i...")
        audio_path = None
        try:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as f:
                f.write(audio_bytes)
                audio_path = f.name

            recognizer = sr.Recognizer()
            with sr.AudioFile(audio_path) as source:
                audio_data = recognizer.record(source)
                try:
                    text = recognizer.recognize_google(audio_data, language="vi-VN")
                    st.success(f"üìù VƒÉn b·∫£n: {text}")
                    st.session_state.user_input_value = text # C·∫≠p nh·∫≠t gi√° tr·ªã input t·ª´ audio
                    st.session_state.audio_processed = True  # ‚úÖ ƒë√°nh d·∫•u ƒë√£ x·ª≠ l√Ω
                    st.rerun() # Rerun ƒë·ªÉ c·∫≠p nh·∫≠t √¥ nh·∫≠p li·ªáu
                except sr.UnknownValueError:
                    st.warning("‚ö†Ô∏è Kh√¥ng nh·∫≠n d·∫°ng ƒë∆∞·ª£c gi·ªçng n√≥i.")
                except sr.RequestError as e:
                    st.error(f"‚ùå L·ªói nh·∫≠n d·∫°ng: {e}")
                finally:
                    if audio_path and os.path.exists(audio_path):
                        os.remove(audio_path)
        except Exception as e:
            st.error(f"‚ùå L·ªói khi x·ª≠ l√Ω file √¢m thanh: {e}")

    # B·ªï sung form b·∫•m g·ª≠i/x√≥a ·ªü d∆∞·ªõi
    with st.form(key='chat_buttons_form'):
        mic_col, send_button_col, clear_button_col = st.columns([9, 1, 1])
        with mic_col:
            # ƒê√¢y l√† √¥ nh·∫≠p li·ªáu ch√≠nh hi·ªán t·∫°i, gi√° tr·ªã ƒë∆∞·ª£c l·∫•y t·ª´ session_state.user_input_value
            # Key c·ªßa text_input gi·ªù l√† user_input_value ƒë·ªÉ n√≥ t·ª± ƒë·ªông c·∫≠p nh·∫≠t session_state ƒë√≥
            user_msg_input_in_form = st.text_input("Nh·∫≠p l·ªánh ho·∫∑c d√πng micro ƒë·ªÉ n√≥i:", value=st.session_state.get("user_input_value", ""), key="user_input_value")
        with send_button_col:
            send_button_pressed = st.form_submit_button("G·ª≠i")
        with clear_button_col:
            clear_button_pressed = st.form_submit_button("X√≥a")

    # ƒê·ªçc c√¢u h·ªèi m·∫´u t·ª´ file JSON
    sample_questions = load_sample_questions()

    # Callback function for selectbox
    def on_sample_question_select():
        # Khi m·ªôt c√¢u h·ªèi m·∫´u ƒë∆∞·ª£c ch·ªçn, c·∫≠p nh·∫≠t user_input_value
        st.session_state.user_input_value = st.session_state.selected_sample_question

    st.markdown("---")
    st.markdown("#### ü§î Ho·∫∑c ch·ªçn c√¢u h·ªèi m·∫´u:")
    # Th√™m c√¢u h·ªèi m·∫´u v√†o selectbox, d√πng callback ƒë·ªÉ c·∫≠p nh·∫≠t input
    st.selectbox(
        "Ch·ªçn m·ªôt c√¢u h·ªèi m·∫´u t·ª´ danh s√°ch",
        options=[""] + sample_questions, # Th√™m option r·ªóng ·ªü ƒë·∫ßu
        key="selected_sample_question",
        on_change=on_sample_question_select
    )
    
    # H√†m ƒë·ªÉ x·ª≠ l√Ω c√¢u h·ªèi v·ªÅ l√£nh ƒë·∫°o x√£
    def handle_lanh_dao(question):
        normalized_question = normalize_text(question)
        
        # Check if the question generally asks about "l√£nh ƒë·∫°o"
        if "l√£nh ƒë·∫°o" in normalized_question:
            try:
                sheet_ld = all_data.get("Danh s√°ch l√£nh ƒë·∫°o x√£, ph∆∞·ªùng")
                if sheet_ld is None or sheet_ld.empty:
                    st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y sheet 'Danh s√°ch l√£nh ƒë·∫°o x√£, ph∆∞·ªùng' ho·∫∑c sheet r·ªóng.")
                    return True

                df_ld = sheet_ld # Already a DataFrame from load_all_sheets
                
                # Find the correct column name for commune/ward
                thuoc_xa_phuong_col = find_column_name(df_ld, ['Thu·ªôc x√£/ph∆∞·ªùng'])
                if not thuoc_xa_phuong_col:
                    st.warning("‚ùó Kh√¥ng t√¨m th·∫•y c·ªôt 'Thu·ªôc x√£/ph∆∞·ªùng' trong sheet 'Danh s√°ch l√£nh ƒë·∫°o x√£, ph∆∞·ªùng'.")
                    return True
                
                # Ensure the column is string type for .str.contains
                df_ld[thuoc_xa_phuong_col] = df_ld[thuoc_xa_phuong_col].astype(str)

                ten_xa_phuong_can_tim = None

                # 1. Try to extract commune/ward name directly using regex
                # This regex captures the word(s) immediately following "x√£" or "ph∆∞·ªùng"
                match_direct = re.search(r'(?:x√£|ph∆∞·ªùng)\s+([\w\s]+)', normalized_question)
                if match_direct:
                    ten_xa_phuong_can_tim = match_direct.group(1).strip()
                
                # 2. If not found by direct regex, try to match against a predefined list of communes/wards
                #    This is a fallback and can also help if the user types just the name without "x√£/ph∆∞·ªùng"
                if not ten_xa_phuong_can_tim:
                    predefined_communes = ["ƒë·ªãnh h√≥a", "kim ph∆∞·ª£ng", "ph∆∞·ª£ng ti·∫øn", "trung h·ªôi", "b√¨nh y√™n", "ph√∫ ƒë√¨nh", "b√¨nh th√†nh", "lam v·ªπ", "b√¨nh h√≤a"] # Added "b√¨nh h√≤a"
                    for keyword in predefined_communes:
                        if keyword in normalized_question:
                            # Try to find the original casing from the unique values in the sheet
                            # This ensures we use the exact name as in the sheet for filtering
                            for sheet_name_original in df_ld[thuoc_xa_phuong_col].unique():
                                if normalize_text(sheet_name_original) == keyword:
                                    ten_xa_phuong_can_tim = sheet_name_original
                                    break
                            if ten_xa_phuong_can_tim:
                                break

                if ten_xa_phuong_can_tim:
                    # Filter DataFrame using the found commune/ward name
                    # Use .str.contains with case=False for case-insensitive matching
                    df_loc = df_ld[df_ld[thuoc_xa_phuong_col].str.contains(ten_xa_phuong_can_tim, case=False, na=False)]
                    
                    if df_loc.empty:
                        st.warning(f"‚ùå Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu l√£nh ƒë·∫°o cho x√£/ph∆∞·ªùng: {ten_xa_phuong_can_tim}. Vui l√≤ng ki·ªÉm tra l·∫°i t√™n x√£/ph∆∞·ªùng ho·∫∑c d·ªØ li·ªáu trong sheet.")
                    else:
                        st.success(f"üìã Danh s√°ch l√£nh ƒë·∫°o x√£/ph∆∞·ªùng {ten_xa_phuong_can_tim}")
                        st.dataframe(df_loc.reset_index(drop=True))
                    return True
                else:
                    st.warning("‚ùó Kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c t√™n x√£/ph∆∞·ªùng trong c√¢u h·ªèi. Vui l√≤ng cung c·∫•p t√™n x√£/ph∆∞·ªùng c·ª• th·ªÉ (v√≠ d·ª•: 'l√£nh ƒë·∫°o x√£ B√¨nh Y√™n').")
                    return True
            except Exception as e:
                st.error(f"L·ªói khi x·ª≠ l√Ω d·ªØ li·ªáu l√£nh ƒë·∫°o x√£: {e}")
                return True
        return False
    
    # H√†m ƒë·ªÉ x·ª≠ l√Ω c√¢u h·ªèi v·ªÅ TBA theo ƒë∆∞·ªùng d√¢y
    def handle_tba(question):
        if "tba" in normalize_text(question) and "ƒë∆∞·ªùng d√¢y" in normalize_text(question):
            try:
                sheet_tba_df = all_data.get("T√™n c√°c TBA") # Get the DataFrame directly
                if sheet_tba_df is None or sheet_tba_df.empty:
                    st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y sheet 'T√™n c√°c TBA' ho·∫∑c sheet r·ªóng.")
                    return True

                # T√¨m c·ªôt 'T√™n ƒë∆∞·ªùng d√¢y' ƒë·ªÉ l·ªçc d·ªØ li·ªáu
                ten_duong_day_col = find_column_name(sheet_tba_df, ['T√™n ƒë∆∞·ªùng d√¢y', 'ƒê∆∞·ªùng d√¢y', 'C'])
                
                if not ten_duong_day_col:
                    st.warning("‚ùó Kh√¥ng t√¨m th·∫•y c·ªôt 'T√™n ƒë∆∞·ªùng d√¢y' trong sheet 'T√™n c√°c TBA'. Vui l√≤ng ki·ªÉm tra l·∫°i t√™n c·ªôt.")
                    return True

                match = re.search(r'(\d{3}E6\.22)', question.upper())
                if match:
                    dd = match.group(1)
                    
                    # L·ªçc d·ªØ li·ªáu d·ª±a tr√™n c·ªôt 'T√™n ƒë∆∞·ªùng d√¢y'
                    df_filtered_by_dd = sheet_tba_df[sheet_tba_df[ten_duong_day_col].astype(str).str.strip().str.contains(dd, case=False, na=False)]
                    
                    if not df_filtered_by_dd.empty:
                        st.success(f"üìÑ Danh s√°ch TBA tr√™n ƒë∆∞·ªùng d√¢y {dd}")
                        st.dataframe(df_filtered_by_dd.reset_index(drop=True))
                    else:
                        st.warning(f"‚ùå Kh√¥ng t√¨m th·∫•y TBA tr√™n ƒë∆∞·ªùng d√¢y {dd}. Vui l√≤ng ki·ªÉm tra l·∫°i m√£ ƒë∆∞·ªùng d√¢y ho·∫∑c d·ªØ li·ªáu trong sheet.")
                    return True
                else:
                    st.warning("‚ùó Vui l√≤ng cung c·∫•p m√£ ƒë∆∞·ªùng d√¢y c√≥ ƒë·ªãnh d·∫°ng XXXE6.22.")
                    return True
            except Exception as e:
                st.error(f"L·ªói khi l·∫•y d·ªØ li·ªáu TBA: {e}")
                return True
        return False
    
    # H√†m ƒë·ªÉ x·ª≠ l√Ω c√¢u h·ªèi v·ªÅ CBCNV
    def handle_cbcnv(question):
        normalized_question = normalize_text(question)
        if "cbcnv" in normalized_question or "c√°n b·ªô c√¥ng nh√¢n vi√™n" in normalized_question:
            try:
                sheet_cbcnv = all_data.get("CBCNV")
                if sheet_cbcnv is None or sheet_cbcnv.empty:
                    st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y sheet 'CBCNV' ho·∫∑c sheet r·ªóng.")
                    return True # ƒê√£ x·ª≠ l√Ω nh∆∞ng kh√¥ng c√≥ d·ªØ li·ªáu

                df = sheet_cbcnv # Already a DataFrame from load_all_sheets

                # --- CBCNV: Bi·ªÉu ƒë·ªì theo b·ªô ph·∫≠n + n√∫t "Ch·ªçn b·ªô ph·∫≠n" ---
                if ("bieu do" in normalized_question or "bi·ªÉu ƒë·ªì" in normalized_question) and ("bo phan" in normalized_question or "b·ªô ph·∫≠n" in normalized_question):
                    dept_col = find_column_name(df, ['B·ªô ph·∫≠n c√¥ng t√°c', 'B·ªô ph·∫≠n', 'B·ªô ph·∫≠n/ng∆∞·ªùi ph·ª• tr√°ch'])
                    if not dept_col:
                        st.warning("‚ùó Kh√¥ng t√¨m th·∫•y c·ªôt 'B·ªô ph·∫≠n c√¥ng t√°c' trong sheet 'CBCNV'.")
                        return True

                    # L√†m s·∫°ch d·ªØ li·ªáu b·ªô ph·∫≠n
                    df[dept_col] = df[dept_col].astype(str).str.strip()
                    df_valid = df[df[dept_col].str.len() > 0].copy()

                    # N√∫t toggle ch·ªçn b·ªô ph·∫≠n
                    state_key = "cbcnv_show_dept_filter"
                    if state_key not in st.session_state:
                        st.session_state[state_key] = False

                    col_btn, col_sp = st.columns([1, 4])
                    with col_btn:
                        if st.button("Ch·ªçn b·ªô ph·∫≠n", key="btn_chon_bo_phan"):
                            st.session_state[state_key] = not st.session_state[state_key]

                    # Danh s√°ch b·ªô ph·∫≠n
                    dept_options = sorted(df_valid[dept_col].dropna().unique().tolist())
                    selected_depts = dept_options
                    if st.session_state[state_key]:
                        selected_depts = st.multiselect("Ch·ªçn b·ªô ph·∫≠n", dept_options, default=dept_options, key="ms_dept")

                    # L·ªçc theo l·ª±a ch·ªçn
                    df_filtered = df_valid[df_valid[dept_col].isin(selected_depts)].copy()

                    # Hi·ªÉn th·ªã b·∫£ng danh s√°ch
                    st.subheader("üìÑ Danh s√°ch CBCNV (l·ªçc theo b·ªô ph·∫≠n)")
                    st.dataframe(df_filtered.reset_index(drop=True))

                    # Nh√≥m theo b·ªô ph·∫≠n
                    counts = df_filtered[dept_col].value_counts().sort_values(ascending=False)
                    if counts.empty:
                        st.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì.")
                        return True

                    # Bi·ªÉu ƒë·ªì c·ªôt
                    fig1, ax1 = plt.subplots(figsize=(12, 6))
                    bars = ax1.bar(counts.index.astype(str), counts.values)
                    ax1.set_title("Ph√¢n b·ªë CBCNV theo b·ªô ph·∫≠n (c·ªôt)")
                    ax1.set_xlabel("B·ªô ph·∫≠n")
                    ax1.set_ylabel("S·ªë l∆∞·ª£ng")
                    ax1.tick_params(axis='x', rotation=45)

                    # G·∫Øn nh√£n s·ªë l√™n c·ªôt
                    for bar in bars:
                        height = bar.get_height()
                        ax1.annotate(f"{int(height)}",
                                     (bar.get_x() + bar.get_width() / 2, height),
                                     ha="center", va="bottom", xytext=(0, 3),
                                     textcoords="offset points", fontsize=10, fontweight="bold")

                    st.pyplot(fig1)
                    plt.close(fig1)

                    # Bi·ªÉu ƒë·ªì tr√≤n
                    fig2, ax2 = plt.subplots(figsize=(8, 8))
                    def _autopct(pct):
                        total = counts.sum()
                        val = int(round(pct * total / 100.0))
                        return f"{val} ({pct:.1f}%)"
                    ax2.pie(counts.values, labels=counts.index.astype(str), autopct=_autopct, startangle=90, counterclock=False)
                    ax2.set_title("Ph√¢n b·ªë CBCNV theo b·ªô ph·∫≠n (tr√≤n)")
                    ax2.axis('equal')
                    st.pyplot(fig2)
                    plt.close(fig2)

                    return True

                # --- CBCNV: Bi·ªÉu ƒë·ªì theo tr√¨nh ƒë·ªô chuy√™n m√¥n ---
                if "tr√¨nh ƒë·ªô chuy√™n m√¥n" in normalized_question:
                    tdcm_col = find_column_name(df, ['Tr√¨nh ƒë·ªô chuy√™n m√¥n', 'Tr√¨nh ƒë·ªô', 'S'])
                    
                    if tdcm_col:
                        # Nh√≥m "K·ªπ s∆∞" v√† "C·ª≠ nh√¢n" v√†o m·ªôt c·ªôt; "Th·∫°c s·ªπ" ƒë·ªÉ ri√™ng
                        df['Nh√≥m Tr√¨nh ƒë·ªô'] = df[tdcm_col].astype(str).apply(lambda x: 
                            'K·ªπ s∆∞ & C·ª≠ nh√¢n' if 'k·ªπ s∆∞' in normalize_text(x) or 'c·ª≠ nh√¢n' in normalize_text(x) else 
                            'Th·∫°c s·ªπ' if 'th·∫°c s·ªπ' in normalize_text(x) else 
                            x # Gi·ªØ nguy√™n c√°c tr√¨nh ƒë·ªô kh√°c
                        )
                        
                        df_grouped = df['Nh√≥m Tr√¨nh ƒë·ªô'].value_counts().reset_index()
                        df_grouped.columns = ['Tr√¨nh ƒë·ªô chuy√™n m√¥n', 'S·ªë l∆∞·ª£ng']

                        st.subheader("üìä Ph√¢n b·ªë CBCNV theo tr√¨nh ƒë·ªô chuy√™n m√¥n")
                        st.dataframe(df_grouped)

                        plt.figure(figsize=(10, 6))
                        ax = sns.barplot(data=df_grouped, x='Tr√¨nh ƒë·ªô chuy√™n m√¥n', y='S·ªë l∆∞·ª£ng', palette='viridis')

                        plt.title("Ph√¢n b·ªë CBCNV theo Tr√¨nh ƒë·ªô Chuy√™n m√¥n", fontsize=16)
                        plt.xlabel("Tr√¨nh ƒë·ªô Chuy√™n m√¥n", fontsize=14)
                        plt.ylabel("S·ªë l∆∞·ª£ng", fontsize=14)
                        
                        for p in ax.patches:
                            ax.annotate(f'{int(p.get_height())}', 
                                        (p.get_x() + p.get_width() / 2., p.get_height()), 
                                        ha='center', 
                                        va='center', 
                                        xytext=(0, 10), 
                                        textcoords='offset points',
                                        fontsize=12,
                                        fontweight='bold')

                        st.pyplot(plt)
                        plt.close()
                        return True
                    else:
                        st.warning("‚ùó Kh√¥ng t√¨m th·∫•y c·ªôt 'Tr√¨nh ƒë·ªô chuy√™n m√¥n' trong sheet CBCNV.")
                        return True

                # --- CBCNV: Bi·ªÉu ƒë·ªì theo ƒë·ªô tu·ªïi ---
                elif "ƒë·ªô tu·ªïi" in normalized_question:
                    tuoi_col = find_column_name(df, ['ƒê·ªô tu·ªïi', 'Tu·ªïi', 'Q'])

                    if tuoi_col:
                        df[tuoi_col] = pd.to_numeric(df[tuoi_col], errors='coerce')
                        bins = [0, 30, 40, 50, 100]
                        labels = ['<30', '30-39', '40-49', '‚â•50']
                        df['Nh√≥m tu·ªïi'] = pd.cut(df[tuoi_col], bins=bins, labels=labels, right=False)
                        df_grouped = df['Nh√≥m tu·ªïi'].value_counts().sort_index().reset_index()
                        df_grouped.columns = ['Nh√≥m tu·ªïi', 'S·ªë l∆∞·ª£ng']

                        st.subheader("üìä Ph√¢n b·ªë CBCNV theo ƒë·ªô tu·ªïi")
                        st.dataframe(df_grouped)

                        plt.figure(figsize=(10, 6))
                        ax = sns.barplot(data=df_grouped, x='Nh√≥m tu·ªïi', y='S·ªë l∆∞·ª£ng', palette='magma')
                        
                        plt.title("Ph√¢n b·ªë CBCNV theo ƒë·ªô tu·ªïi", fontsize=16)
                        plt.xlabel("Nh√≥m tu·ªïi", fontsize=14)
                        plt.ylabel("S·ªë l∆∞·ª£ng", fontsize=14)
                        
                        for p in ax.patches:
                            ax.annotate(f'{int(p.get_height())}',
                                        (p.get_x() + p.get_width() / 2., p.get_height()),
                                        ha='center',
                                        va='center',
                                        xytext=(0, 10),
                                        textcoords='offset points',
                                        fontsize=12,
                                        fontweight='bold')

                        plt.tight_layout()
                        st.pyplot(plt)
                        plt.close()
                        return True
                    else:
                        st.warning("‚ùó Kh√¥ng t√¨m th·∫•y c·ªôt 'ƒê·ªô tu·ªïi' trong sheet CBCNV")
                        return True
                else: # N·∫øu ch·ªâ h·ªèi th√¥ng tin chung v·ªÅ CBCNV
                    st.subheader("üë®‚Äçüë©‚Äçüëß‚Äçüë¶ Danh s√°ch C√°n b·ªô C√¥ng nh√¢n vi√™n")
                    st.dataframe(df.reset_index(drop=True))
                    return True
            except Exception as e:
                st.error(f"L·ªói khi x·ª≠ l√Ω d·ªØ li·ªáu CBCNV: {e}")
                return True
        return False

    # H√†m v·∫Ω bi·ªÉu ƒë·ªì s·ª± c·ªë chung, c√≥ th·ªÉ t√°i s·ª≠ d·ª•ng
    def plot_incident_chart(df, category_col_name, chart_type, year, month=None, is_cumulative=False):
        if not df.empty:
            df_current_year = df[df['thang_nam'].dt.year == year].copy()
            df_previous_year = df[df['thang_nam'].dt.year == year - 1].copy()

            if is_cumulative and month is not None:
                df_current_year = df_current_year[df_current_year['thang_nam'].dt.month <= month]
                df_previous_year = df_previous_year[df_previous_year['thang_nam'].dt.month <= month]
            elif month is not None:
                df_current_year = df_current_year[df_current_year['thang_nam'].dt.month == month]
                df_previous_year = df_previous_year[df_previous_year['thang_nam'].dt.month == month]
            # If month is None and not cumulative, it implies for the whole year

            if not df_current_year.empty or not df_previous_year.empty:
                su_co_current_count = df_current_year[category_col_name].value_counts().reset_index()
                su_co_current_count.columns = [chart_type, 'S·ªë l∆∞·ª£ng s·ª± c·ªë']
                su_co_current_count['NƒÉm'] = year

                su_co_previous_count = df_previous_year[category_col_name].value_counts().reset_index()
                su_co_previous_count.columns = [chart_type, 'S·ªë l∆∞·ª£ng s·ª± c·ªë']
                su_co_previous_count['NƒÉm'] = year - 1
                
                combined_df = pd.concat([su_co_current_count, su_co_previous_count])

                title_prefix = "L≈©y k·∫ø ƒë·∫øn " if is_cumulative and month is not None else ""
                month_str = f"th√°ng {month}/" if month is not None else ""
                chart_title = f"{title_prefix}S·ªë l∆∞·ª£ng s·ª± c·ªë {month_str}{year} so v·ªõi c√πng k·ª≥ nƒÉm {year - 1} theo {chart_type}"
                st.subheader(f"üìä Bi·ªÉu ƒë·ªì {chart_title}")
                st.dataframe(combined_df.reset_index(drop=True))

                plt.figure(figsize=(14, 8))
                ax = sns.barplot(data=combined_df, x=chart_type, y='S·ªë l∆∞·ª£ng s·ª± c·ªë', hue='NƒÉm', palette='viridis')
                
                plt.title(chart_title, fontsize=16)
                plt.xlabel(chart_type, fontsize=14)
                plt.ylabel("S·ªë l∆∞·ª£ng s·ª± c·ªë", fontsize=14)

                for p in ax.patches:
                    ax.annotate(f'{int(p.get_height())}', 
                                (p.get_x() + p.get_width() / 2., p.get_height()), 
                                ha='center', 
                                va='center', 
                                xytext=(0, 10), 
                                textcoords='offset points',
                                fontsize=10,
                                fontweight='bold')
                
                plt.xticks(rotation=45, ha='right')
                plt.tight_layout()
                st.pyplot(plt)
                plt.close()
            else:
                st.warning(f"‚ùó Kh√¥ng c√≥ d·ªØ li·ªáu s·ª± c·ªë n√†o trong kho·∫£ng th·ªùi gian ƒë∆∞·ª£c h·ªèi.")
        else:
            st.warning(f"‚ùó Sheet 'Qu·∫£n l√Ω s·ª± c·ªë' kh√¥ng c√≥ d·ªØ li·ªáu ho·∫∑c kh√¥ng th·ªÉ ƒë·ªçc ƒë∆∞·ª£c.")

    # X·ª≠ l√Ω khi ng∆∞·ªùi d√πng nh·∫•n n√∫t "G·ª≠i"
    if send_button_pressed:
        user_msg = st.session_state.user_input_value
        if user_msg and user_msg != st.session_state.last_processed_user_msg:
            st.session_state.last_processed_user_msg = user_msg
            is_handled = False
            normalized_user_msg = normalize_text(user_msg)
            
            # --- ƒêO·∫†N M√É X·ª¨ L√ù C√ÅC C√ÇU H·ªéI ƒê·ªòNG V·ªÄ S·ª∞ C·ªê ---
            # Regex cho c√¢u h·ªèi c√≥ th√°ng v√† nƒÉm c·ª• th·ªÉ
            incident_month_year_match = re.search(r'(?:th√°ng|l≈©y k·∫ø ƒë·∫øn th√°ng)\s*(\d+)\s*nƒÉm\s*(\d{4}).*v·∫Ω bi·ªÉu ƒë·ªì theo (ƒë∆∞·ªùng d√¢y|t√≠nh ch·∫•t|lo·∫°i s·ª± c·ªë)', normalized_user_msg)
            # Regex cho c√¢u h·ªèi ch·ªâ c√≥ nƒÉm
            incident_year_only_match = re.search(r's·ª± c·ªë nƒÉm\s*(\d{4}).*so s√°nh v·ªõi c√πng k·ª≥, v·∫Ω bi·ªÉu ƒë·ªì theo (ƒë∆∞·ªùng d√¢y|t√≠nh ch·∫•t|lo·∫°i s·ª± c·ªë)', normalized_user_msg)

            if incident_month_year_match or incident_year_only_match:
                sheet_name = "Qu·∫£n l√Ω s·ª± c·ªë"
                sheet_data = all_data.get(sheet_name) # Get DataFrame directly
                
                if sheet_data is not None and not sheet_data.empty:
                    df = sheet_data # Already a DataFrame
                    thang_nam_col = find_column_name(df, ['Th√°ng/NƒÉm s·ª± c·ªë', 'Th√°ng/NƒÉm'])
                    
                    if thang_nam_col:
                        try:
                            df['thang_nam'] = pd.to_datetime(df[thang_nam_col], format='%m/%Y', errors='coerce')
                            df = df.dropna(subset=['thang_nam'])
                            
                            if incident_month_year_match:
                                month = int(incident_month_year_match.group(1))
                                year = int(incident_month_year_match.group(2))
                                chart_type = incident_month_year_match.group(3)
                                is_cumulative = "l≈©y k·∫ø ƒë·∫øn th√°ng" in normalized_user_msg
                            elif incident_year_only_match:
                                year = int(incident_year_only_match.group(1))
                                chart_type = incident_year_only_match.group(2)
                                month = datetime.datetime.now().month # M·∫∑c ƒë·ªãnh l√† th√°ng hi·ªán t·∫°i
                                is_cumulative = True # M·∫∑c ƒë·ªãnh l√† l≈©y k·∫ø ƒë·∫øn th√°ng hi·ªán t·∫°i

                            category_col = None
                            if chart_type == 'ƒë∆∞·ªùng d√¢y':
                                category_col = find_column_name(df, ['ƒê∆∞·ªùng d√¢y', 'ƒê∆∞·ªùng d√¢y s·ª± c·ªë', 'J'])
                            elif chart_type == 't√≠nh ch·∫•t':
                                category_col = find_column_name(df, ['T√≠nh ch·∫•t', 'I'])
                            elif chart_type == 'lo·∫°i s·ª± c·ªë':
                                category_col = find_column_name(df, ['Lo·∫°i s·ª± c·ªë', 'Lo·∫°i', 'E'])

                            if category_col:
                                plot_incident_chart(df, category_col, chart_type, year, month, is_cumulative)
                                is_handled = True
                            else:
                                st.warning(f"‚ùó Kh√¥ng t√¨m th·∫•y c·ªôt ph√¢n lo·∫°i '{chart_type}' trong sheet {sheet_name}.")
                                is_handled = True
                        except Exception as e:
                            st.error(f"‚ùå L·ªói khi x·ª≠ l√Ω d·ªØ li·ªáu s·ª± c·ªë: {e}")
                            is_handled = True
                    else:
                        st.warning(f"‚ùó Kh√¥ng t√¨m th·∫•y c·ªôt 'Th√°ng/NƒÉm s·ª± c·ªë' ho·∫∑c 'Th√°ng/NƒÉm' trong sheet {sheet_name}.")
                        is_handled = True
                else:
                    st.warning(f"‚ùó Sheet '{sheet_name}' kh√¥ng c√≥ d·ªØ li·ªáu ho·∫∑c kh√¥ng th·ªÉ ƒë·ªçc ƒë∆∞·ª£c.")
                is_handled = True
            
            
            # --- KPI th√°ng mm/nƒÉm yyyy (t·ªïng qu√°t, ch·∫°y tr∆∞·ªõc block c·ª©ng 6/2025) ---
            if not is_handled and handle_kpi_monthly(user_msg):
                is_handled = True

# --- X·ª≠ l√Ω c√¢u h·ªèi KPI th√°ng c·ª• th·ªÉ (v√≠ d·ª•: th√°ng 6 nƒÉm 2025) ---
            if "l·∫•y th√¥ng tin kpi c·ªßa c√°c ƒë∆°n v·ªã th√°ng 6 nƒÉm 2025 v√† s·∫Øp x·∫øp theo th·ª© t·ª± gi·∫£m d·∫ßn" in normalized_user_msg:
                sheet_name = "KPI"
                sheet_data = all_data.get(sheet_name) # Get DataFrame directly
                if sheet_data is not None and not sheet_data.empty:
                    df = sheet_data # Already a DataFrame
                    kpi_col = find_column_name(df, ['ƒêi·ªÉm KPI', 'KPI'])
                    nam_col = find_column_name(df, ['NƒÉm'])
                    thang_col = find_column_name(df, ['Th√°ng'])
                    donvi_col = find_column_name(df, ['ƒê∆°n v·ªã'])

                    if kpi_col and nam_col and thang_col and donvi_col:
                        # Chuy·ªÉn ƒë·ªïi d·∫•u ph·∫©y th√†nh d·∫•u ch·∫•m tr∆∞·ªõc khi chuy·ªÉn sang s·ªë
                        df[kpi_col] = df[kpi_col].astype(str).str.replace(',', '.', regex=False)
                        df[kpi_col] = pd.to_numeric(df[kpi_col], errors='coerce')
                        df[nam_col] = pd.to_numeric(df[nam_col], errors='coerce')
                        df[thang_col] = pd.to_numeric(df[thang_col], errors='coerce')

                        # L·ªçc d·ªØ li·ªáu
                        df_filtered = df[(df[nam_col] == 2025) & (df[thang_col] == 6)]
                        donvi_can_v·∫Ω = ["ƒê·ªãnh H√≥a", "ƒê·ªìng H·ª∑", "ƒê·∫°i T·ª´", "Ph√∫ B√¨nh", "Ph√∫ L∆∞∆°ng", "Ph·ªï Y√™n", "S√¥ng C√¥ng", "Th√°i Nguy√™n", "V√µ Nhai"]
                        df_filtered = df_filtered[df_filtered[donvi_col].isin(donvi_can_v·∫Ω)]

                        # S·∫Øp x·∫øp v√† hi·ªÉn th·ªã
                        if not df_filtered.empty: # Only proceed if df_filtered is not empty
                            df_sorted = df_filtered.sort_values(by=kpi_col, ascending=False)
                            st.subheader("üìä KPI c√°c ƒë∆°n v·ªã th√°ng 6 nƒÉm 2025")
                            st.dataframe(df_sorted.reset_index(drop=True))

                            plt.figure(figsize=(10, 6))
                            # ƒê√£ thay ƒë·ªïi: x l√† ƒë∆°n v·ªã, y l√† ƒëi·ªÉm KPI, v√† palette
                            ax = sns.barplot(data=df_sorted, x=donvi_col, y=kpi_col, palette="tab10") # Thay ƒë·ªïi palette
                            plt.title("KPI th√°ng 6/2025 theo ƒë∆°n v·ªã")
                            plt.xlabel("ƒê∆°n v·ªã") # ƒê√£ thay ƒë·ªïi nh√£n tr·ª•c x
                            plt.ylabel("ƒêi·ªÉm KPI") # ƒê√£ thay ƒë·ªïi nh√£n tr·ª•c y
                            plt.xticks(rotation=45, ha='right') # Xoay nh√£n tr·ª•c x
                            plt.tight_layout()

                            # Th√™m gi√° tr·ªã l√™n tr√™n c·ªôt
                            for p in ax.patches:
                                ax.annotate(f'{p.get_height():.2f}', 
                                            (p.get_x() + p.get_width() / 2., p.get_height()), 
                                            ha='center', 
                                            va='center', 
                                            xytext=(0, 10), 
                                            textcoords='offset points',
                                            fontsize=10,
                                            fontweight='bold')

                            st.pyplot(plt)
                            plt.close()
                        else:
                            st.warning("‚ùó Kh√¥ng c√≥ d·ªØ li·ªáu KPI n√†o ƒë·ªÉ hi·ªÉn th·ªã cho th√°ng 6 nƒÉm 2025 v√† c√°c ƒë∆°n v·ªã ƒë√£ ch·ªçn.")
                    else:
                        st.warning(f"‚ùó Kh√¥ng t√¨m th·∫•y ƒë·∫ßy ƒë·ªß c·ªôt (NƒÉm, Th√°ng, ƒê∆°n v·ªã, ƒêi·ªÉm KPI) trong sheet {sheet_name}.")
                else:
                    st.warning(f"‚ùó Sheet '{sheet_name}' kh√¥ng c√≥ d·ªØ li·ªáu ho·∫∑c kh√¥ng th·ªÉ ƒë·ªçc ƒë∆∞·ª£c.")
                is_handled = True
            
            # --- X·ª≠ l√Ω c√¢u h·ªèi KPI l≈©y k·∫ø theo nƒÉm ---
            kpi_cumulative_match = re.search(r'kpi c·ªßa c√°c ƒë∆°n v·ªã l≈©y k·∫ø nƒÉm (\d{4}) v√† s·∫Øp x·∫øp theo th·ª© t·ª± gi·∫£m d·∫ßn', normalized_user_msg)
            if kpi_cumulative_match:
                target_year = int(kpi_cumulative_match.group(1))

                sheet_name = "KPI"
                sheet_data = all_data.get(sheet_name) # Get DataFrame directly
                if sheet_data is not None and not sheet_data.empty:
                    df = sheet_data # Already a DataFrame
                    kpi_col = find_column_name(df, ['ƒêi·ªÉm KPI', 'KPI'])
                    nam_col = find_column_name(df, ['NƒÉm'])
                    thang_col = find_column_name(df, ['Th√°ng'])
                    donvi_col = find_column_name(df, ['ƒê∆°n v·ªã'])

                    if kpi_col and nam_col and thang_col and donvi_col:
                        # Chu·∫©n h√≥a d·ªØ li·ªáu KPI
                        df[kpi_col] = df[kpi_col].astype(str).str.replace(',', '.', regex=False)
                        df[kpi_col] = pd.to_numeric(df[kpi_col], errors='coerce')
                        df[nam_col] = pd.to_numeric(df[nam_col], errors='coerce')
                        df[thang_col] = pd.to_numeric(df[thang_col], errors='coerce')

                        # L·ªçc d·ªØ li·ªáu cho nƒÉm m·ª•c ti√™u
                        df_filtered_year = df[(df[nam_col] == target_year)].copy()
                        
                        if not df_filtered_year.empty:
                            # ƒê√£ thay ƒë·ªïi: T√≠nh KPI l≈©y k·∫ø (trung b√¨nh c√°c th√°ng) cho m·ªói ƒë∆°n v·ªã trong nƒÉm ƒë√≥
                            df_kpi_cumulative = df_filtered_year.groupby(donvi_col)[kpi_col].mean().reset_index()
                            df_kpi_cumulative.columns = ['ƒê∆°n v·ªã', 'ƒêi·ªÉm KPI L≈©y k·∫ø (Trung b√¨nh)'] # C·∫≠p nh·∫≠t t√™n c·ªôt
                            df_kpi_cumulative = df_kpi_cumulative.sort_values(by='ƒêi·ªÉm KPI L≈©y k·∫ø (Trung b√¨nh)', ascending=False)

                            st.subheader(f"üìä KPI l≈©y k·∫ø (Trung b√¨nh) nƒÉm {target_year} c·ªßa c√°c ƒë∆°n v·ªã")
                            st.dataframe(df_kpi_cumulative.reset_index(drop=True))

                            plt.figure(figsize=(12, 7))
                            # S·ª≠ d·ª•ng palette ƒë·ªÉ m·ªói c·ªôt c√≥ m√†u ri√™ng bi·ªát
                            ax = sns.barplot(data=df_kpi_cumulative, x='ƒê∆°n v·ªã', y='ƒêi·ªÉm KPI L≈©y k·∫ø (Trung b√¨nh)', palette='hls')
                            plt.title(f"KPI l≈©y k·∫ø (Trung b√¨nh) nƒÉm {target_year} theo ƒë∆°n v·ªã", fontsize=16)
                            plt.xlabel("ƒê∆°n v·ªã", fontsize=14)
                            plt.ylabel("ƒêi·ªÉm KPI L≈©y k·∫ø (Trung b√¨nh)", fontsize=14)
                            plt.xticks(rotation=45, ha='right') # Xoay nh√£n tr·ª•c x ƒë·ªÉ d·ªÖ ƒë·ªçc
                            plt.grid(axis='y', linestyle='--', alpha=0.7)

                            # Hi·ªÉn th·ªã gi√° tr·ªã tr√™n ƒë·ªânh c·ªôt
                            for p in ax.patches:
                                ax.annotate(f'{p.get_height():.2f}', 
                                            (p.get_x() + p.get_width() / 2., p.get_height()), 
                                            ha='center', 
                                            va='center', 
                                            xytext=(0, 10), 
                                            textcoords='offset points',
                                            fontsize=10,
                                            fontweight='bold')

                            plt.tight_layout()
                            st.pyplot(plt)
                            plt.close()
                        else:
                            st.warning(f"‚ùó Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu KPI cho nƒÉm {target_year}. Vui l√≤ng ki·ªÉm tra l·∫°i d·ªØ li·ªáu trong sheet.")
                    else:
                        st.warning(f"‚ùó Kh√¥ng t√¨m th·∫•y ƒë·∫ßy ƒë·ªß c·ªôt (NƒÉm, Th√°ng, ƒê∆°n v·ªã, ƒêi·ªÉm KPI) trong sheet {sheet_name}.")
                else:
                    st.warning(f"‚ùó Sheet '{sheet_name}' kh√¥ng c√≥ d·ªØ li·ªáu ho·∫∑c kh√¥ng th·ªÉ ƒë·ªçc ƒë∆∞·ª£c.")
                is_handled = True
            
            # --- X·ª≠ l√Ω c√¢u h·ªèi so s√°nh KPI theo nƒÉm cho m·ªôt ƒë∆°n v·ªã c·ª• th·ªÉ ---
            kpi_compare_match = re.search(r'kpi nƒÉm (\d{4}) c·ªßa ([\w\s]+) so s√°nh v·ªõi c√°c nƒÉm tr∆∞·ªõc', normalized_user_msg)
            if kpi_compare_match:
                target_year = int(kpi_compare_match.group(1))
                target_donvi = kpi_compare_match.group(2).strip()

                sheet_name = "KPI"
                sheet_data = all_data.get(sheet_name) # Get DataFrame directly
                if sheet_data is not None and not sheet_data.empty:
                    df = sheet_data # Already a DataFrame
                    kpi_col = find_column_name(df, ['ƒêi·ªÉm KPI', 'KPI'])
                    nam_col = find_column_name(df, ['NƒÉm'])
                    thang_col = find_column_name(df, ['Th√°ng'])
                    donvi_col = find_column_name(df, ['ƒê∆°n v·ªã'])

                    if kpi_col and nam_col and thang_col and donvi_col:
                        # Chu·∫©n h√≥a d·ªØ li·ªáu KPI
                        df[kpi_col] = df[kpi_col].astype(str).str.replace(',', '.', regex=False)
                        df[kpi_col] = pd.to_numeric(df[kpi_col], errors='coerce')
                        df[nam_col] = pd.to_numeric(df[nam_col], errors='coerce')
                        df[thang_col] = pd.to_numeric(df[thang_col], errors='coerce')

                        # L·ªçc d·ªØ li·ªáu cho ƒë∆°n v·ªã m·ª•c ti√™u
                        df_filtered_donvi = df[df[donvi_col].str.lower() == target_donvi.lower()].copy()
                        
                        if not df_filtered_donvi.empty:
                            # L·∫•y c√°c nƒÉm c√≥ d·ªØ li·ªáu cho ƒë∆°n v·ªã n√†y, bao g·ªìm nƒÉm m·ª•c ti√™u v√† c√°c nƒÉm tr∆∞·ªõc ƒë√≥
                            # L·∫•y t·ªëi ƒëa 4 nƒÉm g·∫ßn nh·∫•t bao g·ªìm nƒÉm m·ª•c ti√™u
                            years_to_plot = sorted(df_filtered_donvi[nam_col].dropna().unique().tolist(), reverse=True)
                            years_to_plot = [y for y in years_to_plot if y <= target_year][:4] # Gi·ªõi h·∫°n 4 nƒÉm g·∫ßn nh·∫•t
                            years_to_plot.sort() # S·∫Øp x·∫øp l·∫°i theo th·ª© t·ª± tƒÉng d·∫ßn ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì

                            if not years_to_plot:
                                st.warning(f"‚ùó Kh√¥ng c√≥ d·ªØ li·ªáu KPI cho ƒë∆°n v·ªã '{target_donvi}' trong c√°c nƒÉm g·∫ßn ƒë√¢y.")
                                is_handled = True
                                # continue # This continue is for a loop, but here it's inside an if, so it would break the flow.
                            else:
                                # Create a DataFrame for plotting, including only relevant columns
                                plot_df = df_filtered_donvi[df_filtered_donvi[nam_col].isin(years_to_plot)][[nam_col, thang_col, kpi_col]].copy()
                                plot_df = plot_df.dropna(subset=[kpi_col, thang_col, nam_col])
                                plot_df[thang_col] = plot_df[thang_col].astype(int)
                                plot_df[nam_col] = plot_df[nam_col].astype(int)
                                
                                # Sort by year and month for correct line plotting
                                plot_df = plot_df.sort_values(by=[nam_col, thang_col])

                                st.subheader(f"üìä So s√°nh KPI c·ªßa {target_donvi} qua c√°c th√°ng")
                                st.dataframe(plot_df)

                                plt.figure(figsize=(12, 7))
                                
                                # Plot each year as a separate line
                                for year in years_to_plot:
                                    year_data = plot_df[plot_df[nam_col] == year].copy()
                                    
                                    # For the target year, only plot up to the last available month
                                    if year == target_year:
                                        if not year_data.empty:
                                            max_month_current_year = year_data[thang_col].max()
                                            year_data = year_data[year_data[thang_col] <= max_month_current_year]
                                        else:
                                            st.warning(f"‚ùó Kh√¥ng c√≥ d·ªØ li·ªáu KPI cho nƒÉm {target_year} c·ªßa ƒë∆°n v·ªã '{target_donvi}'.")
                                            continue # Skip plotting for this year if no data

                                    if not year_data.empty:
                                        sns.lineplot(data=year_data, x=thang_col, y=kpi_col, marker='o', label=str(year))
                                        
                                        # Add annotations for all years plotted
                                        for x_val, y_val in zip(year_data[thang_col], year_data[kpi_col]):
                                            plt.text(x_val, y_val, f'{y_val:.2f}', ha='center', va='bottom', fontsize=9)


                                plt.title(f"So s√°nh KPI c·ªßa {target_donvi} qua c√°c th√°ng theo nƒÉm")
                                plt.xlabel("Th√°ng")
                                plt.ylabel("ƒêi·ªÉm KPI")
                                plt.xticks(range(1, 13)) # Ensure x-axis shows months 1-12
                                plt.xlim(0.5, 12.5) # Set x-axis limits to clearly show months 1-12
                                plt.grid(True, linestyle='--', alpha=0.7)
                                plt.legend(title="NƒÉm")
                                plt.tight_layout()
                                st.pyplot(plt)
                                plt.close()
                        else:
                            st.warning(f"‚ùó Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu KPI cho ƒë∆°n v·ªã '{target_donvi}'. Vui l√≤ng ki·ªÉm tra l·∫°i t√™n ƒë∆°n v·ªã.")
                    else:
                        st.warning(f"‚ùó Kh√¥ng t√¨m th·∫•y ƒë·∫ßy ƒë·ªß c·ªôt (NƒÉm, Th√°ng, ƒê∆°n v·ªã, ƒêi·ªÉm KPI) trong sheet {sheet_name}.")
                else:
                    st.warning(f"‚ùó Sheet '{sheet_name}' kh√¥ng c√≥ d·ªØ li·ªáu ho·∫∑c kh√¥ng th·ªÉ ƒë·ªçc ƒë∆∞·ª£c.")
                is_handled = True
            
            # --- X·ª≠ l√Ω c√¢u h·ªèi v·ªÅ TBA theo c√¥ng su·∫•t ---
            tba_capacity_match = re.search(r'c√¥ng su·∫•t\s*(\d+)\s*kva', normalized_user_msg)
            if tba_capacity_match:
                target_capacity_num = tba_capacity_match.group(1)
                target_capacity = f"{target_capacity_num}KVA" # Reconstruct to match data format in sheet

                sheet_name = "T√™n c√°c TBA"
                sheet_data = all_data.get(sheet_name)
                if sheet_data is not None and not sheet_data.empty:
                    df = sheet_data

                    cong_suat_col = find_column_name(df, ['C√¥ng su·∫•t', 'C√¥ng su·∫•t ']) # Include both with and without space
                    if cong_suat_col:
                        # Normalize the column data for robust comparison (remove spaces, convert to upper)
                        df_filtered_by_capacity = df[
                            df[cong_suat_col].astype(str).str.replace(' ', '').str.upper() == target_capacity.upper()
                        ]

                        if not df_filtered_by_capacity.empty:
                            st.success(f"üìÑ Danh s√°ch TBA c√≥ c√¥ng su·∫•t {target_capacity}")
                            st.dataframe(df_filtered_by_capacity.reset_index(drop=True))
                        else:
                            st.warning(f"‚ùå Kh√¥ng t√¨m th·∫•y TBA c√≥ c√¥ng su·∫•t {target_capacity}. Vui l√≤ng ki·ªÉm tra l·∫°i c√¥ng su·∫•t ho·∫∑c d·ªØ li·ªáu trong sheet.")
                        is_handled = True
                    else:
                        st.warning(f"‚ùó Kh√¥ng t√¨m th·∫•y c·ªôt 'C√¥ng su·∫•t' trong sheet {sheet_name}.")
                        is_handled = True
                else:
                    st.warning(f"‚ùó Sheet '{sheet_name}' kh√¥ng c√≥ d·ªØ li·ªáu ho·∫∑c kh√¥ng th·ªÉ ƒë·ªçc ƒë∆∞·ª£c.")
                is_handled = True

            # --- ƒêO·∫†N M√É X·ª¨ L√ù C√ÅC C√ÇU H·ªéI KH√ÅC ---
            if not is_handled:
                if handle_lanh_dao(user_msg): # G·ªçi h√†m handle_lanh_dao ·ªü ƒë√¢y
                    is_handled = True
                elif handle_tba(user_msg):
                    is_handled = True
                elif handle_cbcnv(user_msg):
                    is_handled = True
                elif not qa_df.empty:
                    # Ki·ªÉm tra v√† l·∫•y c√¢u tr·∫£ l·ªùi t·ª´ Google Sheets
                    qa_df['normalized_question'] = qa_df['C√¢u h·ªèi'].apply(normalize_text)
                    qa_df['similarity'] = qa_df['normalized_question'].apply(lambda x: fuzz.ratio(normalized_user_msg, x))
                    
                    matches = qa_df[qa_df['similarity'] > 80].sort_values(by='similarity', ascending=False)

                    if not matches.empty:
                        st.session_state.qa_results = matches.to_dict('records')
                        st.session_state.qa_index = 0
                        
                        # Hi·ªÉn th·ªã c√¢u tr·∫£ l·ªùi ƒë·∫ßu ti√™n
                        first_match = st.session_state.qa_results[0]
                        st.session_state.current_qa_display = first_match['C√¢u tr·∫£ l·ªùi']
                        st.success(f"‚úÖ T√¨m th·∫•y c√¢u tr·∫£ l·ªùi ph√π h·ª£p (ƒê·ªô t∆∞∆°ng t·ª±: {first_match['similarity']}%):")
                        st.markdown(st.session_state.current_qa_display)
                        
                        is_handled = True
                    else:
                        st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y c√¢u tr·∫£ l·ªùi ph√π h·ª£p trong c∆° s·ªü d·ªØ li·ªáu. Vui l√≤ng nh·∫≠p l·∫°i c√¢u h·ªèi ho·∫∑c th·ª≠ c√¢u h·ªèi kh√°c.")
                
            if not is_handled:
                # X·ª≠ l√Ω khi kh√¥ng c√≥ c√¢u h·ªèi n√†o ƒë∆∞·ª£c kh·ªõp
                # Ki·ªÉm tra xem c√≥ OpenAI API key kh√¥ng tr∆∞·ªõc khi g·ªçi API
                if client_ai:
                    with st.spinner("ƒêang t√¨m c√¢u tr·∫£ l·ªùi b·∫±ng AI..."):
                        try:
                            prompt_text = f"Ng∆∞·ªùi d√πng h·ªèi: \"{user_msg}\". H√£y tr·∫£ l·ªùi m·ªôt c√°ch l·ªãch s·ª±, th√¢n thi·ªán v√† ng·∫Øn g·ªçn r·∫±ng b·∫°n ch·ªâ c√≥ th·ªÉ tr·∫£ l·ªùi c√°c c√¢u h·ªèi li√™n quan ƒë·∫øn d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c cung c·∫•p. N·∫øu c√¢u h·ªèi kh√¥ng c√≥ trong d·ªØ li·ªáu, h√£y ƒë·ªÅ xu·∫•t ng∆∞·ªùi d√πng nh·∫≠p l·∫°i ho·∫∑c s·ª≠ d·ª•ng m·ªôt c√¢u h·ªèi m·∫´u kh√°c."
                            
                            response = client_ai.chat.completions.create(
                                model="gpt-3.5-turbo",
                                messages=[
                                    {"role": "system", "content": "B·∫°n l√† m·ªôt tr·ª£ l√Ω ·∫£o c·ªßa ƒê·ªôi QLƒêLKV ƒê·ªãnh H√≥a. B·∫°n ch·ªâ tr·∫£ l·ªùi c√°c c√¢u h·ªèi d·ª±a tr√™n c√°c d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c cung c·∫•p. H√£y tr·∫£ l·ªùi m·ªôt c√°ch chuy√™n nghi·ªáp, l·ªãch s·ª±, ng·∫Øn g·ªçn v√† h·ªØu √≠ch. N·∫øu c√¢u h·ªèi kh√¥ng li√™n quan ƒë·∫øn d·ªØ li·ªáu, h√£y t·ª´ ch·ªëi tr·∫£ l·ªùi m·ªôt c√°ch kh√©o l√©o."},
                                    {"role": "user", "content": prompt_text}
                                ],
                                max_tokens=150
                            )
                            st.info("üí° Tr·∫£ l·ªùi t·ª´ AI:")
                            st.markdown(response.choices[0].message.content)
                        except Exception as e:
                            st.error(f"‚ùå L·ªói khi g·ªçi OpenAI API: {e}. Vui l√≤ng ki·ªÉm tra l·∫°i API key ho·∫∑c k·∫øt n·ªëi m·∫°ng.")
                else:
                    st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y c√¢u tr·∫£ l·ªùi ph√π h·ª£p trong c∆° s·ªü d·ªØ li·ªáu v√† kh√¥ng c√≥ OpenAI API key ƒë∆∞·ª£c c·∫•u h√¨nh ƒë·ªÉ s·ª≠ d·ª•ng AI. Vui l√≤ng nh·∫≠p l·∫°i c√¢u h·ªèi ho·∫∑c th·ª≠ c√¢u h·ªèi kh√°c.")

        elif clear_button_pressed:
            st.session_state.user_input_value = "" # ƒê·∫∑t l·∫°i √¥ nh·∫≠p li·ªáu
            st.session_state.last_processed_user_msg = ""
            st.session_state.qa_results = []
            st.session_state.qa_index = 0
            st.session_state.current_qa_display = ""
            st.session_state.audio_processed = False
            st.rerun()

    # ƒêi·ªÅu h∆∞·ªõng gi·ªØa c√°c c√¢u tr·∫£ l·ªùi
    if st.session_state.qa_results:
        st.markdown("---")
        qa_col1, qa_col2, qa_col3 = st.columns([1, 1, 1])

        with qa_col1:
            if st.button("C√¢u tr·∫£ l·ªùi tr∆∞·ªõc ƒë√≥"):
                st.session_state.qa_index = max(0, st.session_state.qa_index - 1)
                st.session_state.current_qa_display = st.session_state.qa_results[st.session_state.qa_index]['C√¢u tr·∫£ l·ªùi']
                st.rerun()

        with qa_col2:
            st.markdown(f"<p style='text-align: center;'>{st.session_state.qa_index + 1}/{len(st.session_state.qa_results)}</p>", unsafe_allow_html=True)
        
        with qa_col3:
            if st.button("C√¢u tr·∫£ l·ªùi ti·∫øp theo"):
                st.session_state.qa_index = min(len(st.session_state.qa_results) - 1, st.session_state.qa_index + 1)
                st.session_state.current_qa_display = st.session_state.qa_results[st.session_state.qa_index]['C√¢u tr·∫£ l·ªùi']
                st.rerun()
        
        # Hi·ªÉn th·ªã c√¢u tr·∫£ l·ªùi hi·ªán t·∫°i sau khi ƒë√£ ƒëi·ªÅu h∆∞·ªõng
        if st.session_state.current_qa_display:
            st.success(f"‚úÖ C√¢u tr·∫£ l·ªùi (ƒê·ªô t∆∞∆°ng t·ª±: {st.session_state.qa_results[st.session_state.qa_index]['similarity']}%):")
            st.markdown(st.session_state.current_qa_display)
        
        if len(st.session_state.qa_results) and len(st.session_state.qa_results) > 1:
            st.info("ƒê√£ hi·ªÉn th·ªã t·∫•t c·∫£ c√°c c√¢u tr·∫£ l·ªùi t∆∞∆°ng t·ª±.")


    def extract_text_from_image(image_path):
        reader = easyocr.Reader(['vi'])
        result = reader.readtext(image_path, detail=0)
        text = " ".join(result)
        return text

    st.markdown("### üì∏ Ho·∫∑c t·∫£i ·∫£nh ch·ª©a c√¢u h·ªèi (n·∫øu c√≥)")
    uploaded_image = st.file_uploader("T·∫£i ·∫£nh c√¢u h·ªèi", type=["jpg", "png", "jpeg"])

    if uploaded_image is not None:
        temp_image_path = Path("temp_uploaded_image.jpg")
        try:
            with open(temp_image_path, "wb") as f:
                f.write(uploaded_image.getbuffer())
            
            with st.spinner("‚è≥ ƒêang x·ª≠ l√Ω ·∫£nh v√† tr√≠ch xu·∫•t vƒÉn b·∫£n..."):
                extracted_text = extract_text_from_image(str(temp_image_path))
            
            if extracted_text:
                st.info("VƒÉn b·∫£n ƒë∆∞·ª£c tr√≠ch xu·∫•t t·ª´ ·∫£nh:")
                st.code(extracted_text, language="text")
                st.session_state.user_input_value = extracted_text
                st.success("‚úÖ ƒê√£ ƒëi·ªÅn vƒÉn b·∫£n v√†o √¥ nh·∫≠p li·ªáu. B·∫°n c√≥ th·ªÉ ch·ªânh s·ª≠a v√† nh·∫•n 'G·ª≠i'.")
                st.rerun()
            else:
                st.warning("‚ö†Ô∏è Kh√¥ng th·ªÉ tr√≠ch xu·∫•t vƒÉn b·∫£n t·ª´ ·∫£nh. Vui l√≤ng th·ª≠ l·∫°i v·ªõi ·∫£nh kh√°c r√µ h∆°n.")
        finally:
            if temp_image_path.exists():
                os.remove(temp_image_path)
